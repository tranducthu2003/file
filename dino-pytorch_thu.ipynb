{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "e5f0acbf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:48:16.256374Z",
          "iopub.status.busy": "2024-11-21T10:48:16.256025Z",
          "iopub.status.idle": "2024-11-21T10:48:16.260153Z",
          "shell.execute_reply": "2024-11-21T10:48:16.259463Z"
        },
        "papermill": {
          "duration": 0.012962,
          "end_time": "2024-11-21T10:48:16.261693",
          "exception": false,
          "start_time": "2024-11-21T10:48:16.248731",
          "status": "completed"
        },
        "tags": [],
        "id": "e5f0acbf"
      },
      "outputs": [],
      "source": [
        "# !pip install typing_extensions==4.7.1\n",
        "# import typing_extensions\n",
        "# from importlib import reload\n",
        "# reload(typing_extensions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "9a9d81df",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T06:08:42.433591Z",
          "iopub.status.busy": "2024-11-21T06:08:42.432869Z",
          "iopub.status.idle": "2024-11-21T06:08:42.437892Z",
          "shell.execute_reply": "2024-11-21T06:08:42.437084Z",
          "shell.execute_reply.started": "2024-11-21T06:08:42.433552Z"
        },
        "papermill": {
          "duration": 0.005119,
          "end_time": "2024-11-21T10:48:16.273522",
          "exception": false,
          "start_time": "2024-11-21T10:48:16.268403",
          "status": "completed"
        },
        "tags": [],
        "id": "9a9d81df"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "053df61e",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-11-21T10:48:16.284944Z",
          "iopub.status.busy": "2024-11-21T10:48:16.284690Z",
          "iopub.status.idle": "2024-11-21T10:49:12.813022Z",
          "shell.execute_reply": "2024-11-21T10:49:12.812045Z"
        },
        "papermill": {
          "duration": 56.536111,
          "end_time": "2024-11-21T10:49:12.814855",
          "exception": false,
          "start_time": "2024-11-21T10:48:16.278744",
          "status": "completed"
        },
        "tags": [],
        "id": "053df61e",
        "outputId": "160a7e82-64ea-4b4f-a9fd-0a6aab7568a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepspeed in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed) (3.1.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.1.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.11.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.9.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.66.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->deepspeed) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->deepspeed) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->deepspeed) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (3.0.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "# hide\n",
        "!pip install deepspeed\n",
        "!pip install --upgrade wandb\n",
        "import copy\n",
        "from functools import partial\n",
        "import multiprocessing as mp\n",
        "from pathlib import Path\n",
        "from typing import Any, Callable, List, Tuple\n",
        "import os\n",
        "from PIL import Image\n",
        "import PIL.ImageOps\n",
        "from PIL import ImageFile\n",
        "import math\n",
        "import json\n",
        "import time\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "\n",
        "\n",
        "from deepspeed.ops.adam import FusedAdam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.distributions.bernoulli import Bernoulli\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import io, transforms\n",
        "# from torchvision.utils import Image, ImageDraw\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from tqdm.auto import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "e1040a48",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:49:12.831471Z",
          "iopub.status.busy": "2024-11-21T10:49:12.831191Z",
          "iopub.status.idle": "2024-11-21T10:49:12.853084Z",
          "shell.execute_reply": "2024-11-21T10:49:12.852291Z"
        },
        "papermill": {
          "duration": 0.032287,
          "end_time": "2024-11-21T10:49:12.854749",
          "exception": false,
          "start_time": "2024-11-21T10:49:12.822462",
          "status": "completed"
        },
        "tags": [],
        "id": "e1040a48",
        "outputId": "3e898044-1326-4f63-9ff3-9ba3543cadc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive')\n",
        "\n",
        "import utils1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "4941496a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:49:12.871993Z",
          "iopub.status.busy": "2024-11-21T10:49:12.871753Z",
          "iopub.status.idle": "2024-11-21T10:49:12.875590Z",
          "shell.execute_reply": "2024-11-21T10:49:12.874802Z"
        },
        "papermill": {
          "duration": 0.013648,
          "end_time": "2024-11-21T10:49:12.877136",
          "exception": false,
          "start_time": "2024-11-21T10:49:12.863488",
          "status": "completed"
        },
        "tags": [],
        "id": "4941496a"
      },
      "outputs": [],
      "source": [
        "def is_image_file(filename):\n",
        "#    return filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))\n",
        "    return filename.lower().endswith(('.png', '.jpg', '.jpeg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "bc654d6c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:49:12.892800Z",
          "iopub.status.busy": "2024-11-21T10:49:12.892525Z",
          "iopub.status.idle": "2024-11-21T10:49:12.897335Z",
          "shell.execute_reply": "2024-11-21T10:49:12.896526Z"
        },
        "papermill": {
          "duration": 0.014207,
          "end_time": "2024-11-21T10:49:12.898855",
          "exception": false,
          "start_time": "2024-11-21T10:49:12.884648",
          "status": "completed"
        },
        "tags": [],
        "id": "bc654d6c"
      },
      "outputs": [],
      "source": [
        "# Image parameters\n",
        "TRAIN_FILES = \"/kaggle/input/spamv1/spamimg_train/Products\"\n",
        "IMAGE_SIZE = 256\n",
        "PATCH_SIZE = 16\n",
        "ZERO_PCT = 0.1\n",
        "PATCHES_PER_ROW = (IMAGE_SIZE // PATCH_SIZE)\n",
        "NUM_PATCHES = PATCHES_PER_ROW ** 2\n",
        "RGB_CHANNELS = 3\n",
        "NUM_PIXELS = PATCH_SIZE ** 2 * RGB_CHANNELS\n",
        "VALID_IMAGES = 5\n",
        "TOPK = 5\n",
        "\n",
        "# Training parameters\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "LR = 1e-4\n",
        "\n",
        "# Transformer parameters\n",
        "N_HEADS = 8\n",
        "N_LAYERS = 6\n",
        "\n",
        "# Update constants\n",
        "TEMPERATURE_S = 0.1\n",
        "TEMPERATURE_T = 0.05\n",
        "CENTER_MOMENTUM = 0.9\n",
        "TEACHER_MOMENTUM = 0.995"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "8ef0bcaf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:49:12.914113Z",
          "iopub.status.busy": "2024-11-21T10:49:12.913869Z",
          "iopub.status.idle": "2024-11-21T10:49:12.918990Z",
          "shell.execute_reply": "2024-11-21T10:49:12.918192Z"
        },
        "papermill": {
          "duration": 0.014499,
          "end_time": "2024-11-21T10:49:12.920519",
          "exception": false,
          "start_time": "2024-11-21T10:49:12.906020",
          "status": "completed"
        },
        "tags": [],
        "id": "8ef0bcaf"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    BATCH_SIZE = 16\n",
        "    num_workers = 4\n",
        "    WeightSampler = True\n",
        "    seed = 122\n",
        "\n",
        "    model_name = \"swin_v2_t\"\n",
        "    pretrained = True\n",
        "\n",
        "    learning_rate = 5e-6\n",
        "    weight_decay = 1e-6\n",
        "\n",
        "    embedding_size = 512\n",
        "    loss_function = \"\" # ContrastiveLoss else BCE loss\n",
        "    replace_fc = False\n",
        "\n",
        "    threshold = 0.5\n",
        "    # margin for contrastive loss\n",
        "    margin = 9.5\n",
        "\n",
        "    EPOCHS = 10\n",
        "    early_stopping = 25\n",
        "\n",
        "    model_path = \"/kaggle/input/bigdataset-models\" # Dir to load model to test\n",
        "    output_dir = \"/kaggle/working/\" # Dir to save model after train\n",
        "    mode = \"\" # Training or Inference else All\n",
        "                        #if mode is All set model_path and output_dir to \"\"\n",
        "    # Dataset\n",
        "    ratio = 0.80\n",
        "    SKFold = True\n",
        "    train_dir = \"/kaggle/input/spamv2/SelectedP6\"\n",
        "    train_csv = \"/kaggle/input/dataset-csvs/v5/paired_train_big_10000_1_1_.csv\"\n",
        "\n",
        "    test_dir = \"/kaggle/input/spamv2/SelectedP6\"\n",
        "    test_csv = \"/kaggle/input/csvfile/balanced_test_part6.csv\"\n",
        "\n",
        "    online_pairing = False\n",
        "    neg_ratio = 1\n",
        "    pos_ratio = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "d2b13018",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:49:12.936073Z",
          "iopub.status.busy": "2024-11-21T10:49:12.935810Z",
          "iopub.status.idle": "2024-11-21T10:49:12.945315Z",
          "shell.execute_reply": "2024-11-21T10:49:12.944514Z"
        },
        "papermill": {
          "duration": 0.019187,
          "end_time": "2024-11-21T10:49:12.946999",
          "exception": false,
          "start_time": "2024-11-21T10:49:12.927812",
          "status": "completed"
        },
        "tags": [],
        "id": "d2b13018"
      },
      "outputs": [],
      "source": [
        "class ImageData(Dataset):\n",
        "    def __init__(self, files: List[str]):\n",
        "        self.files = files\n",
        "\n",
        "        self.to_tensor = transforms.PILToTensor()\n",
        "        self.randcrop_big = transforms.RandomResizedCrop((IMAGE_SIZE, IMAGE_SIZE), scale=(0.5, 1.0))\n",
        "        self.randcrop_small = transforms.RandomResizedCrop((IMAGE_SIZE, IMAGE_SIZE))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        img = Image.open((self.files[i]))\n",
        "        img = img.convert('RGB')\n",
        "        #img = self.to_tensor(img)\n",
        "\n",
        "        img1 = self.randcrop_big(img)\n",
        "        img2 = self.randcrop_small(img)\n",
        "\n",
        "        # img1 = self.to_tensor(img1)\n",
        "        # img2 = self.to_tensor(img2)\n",
        "\n",
        "        if  self.to_tensor(img).shape[0] == 1:\n",
        "            img1 = torch.cat([img1]*3)\n",
        "            img2 = torch.cat([img2]*3)\n",
        "\n",
        "        return self.to_tensor(img1), self.to_tensor(img2)\n",
        "\n",
        "class CollateFn:\n",
        "    def reshape(self, batch):\n",
        "        patches = torch.stack(batch)\\\n",
        "                    .unfold(2, PATCH_SIZE, PATCH_SIZE)\\\n",
        "                    .unfold(3, PATCH_SIZE, PATCH_SIZE)\n",
        "\n",
        "        num_images = len(patches)\n",
        "        patches = patches.reshape(\n",
        "            num_images,\n",
        "            RGB_CHANNELS,\n",
        "            NUM_PATCHES,\n",
        "            PATCH_SIZE,\n",
        "            PATCH_SIZE\n",
        "        )\n",
        "        patches.transpose_(1, 2)\n",
        "\n",
        "        return patches.reshape(num_images, NUM_PATCHES, -1) / 255.0 - 0.5\n",
        "\n",
        "    def __call__(\n",
        "        self, batch: List[Tuple[torch.Tensor, torch.Tensor]]\n",
        "    ) -> Tuple[torch.FloatTensor, torch.FloatTensor]:\n",
        "        x1, x2 = zip(*batch)\n",
        "\n",
        "        return self.reshape(x1), self.reshape(x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "99370201",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:49:12.962294Z",
          "iopub.status.busy": "2024-11-21T10:49:12.962054Z",
          "iopub.status.idle": "2024-11-21T10:49:12.967529Z",
          "shell.execute_reply": "2024-11-21T10:49:12.966763Z"
        },
        "papermill": {
          "duration": 0.014853,
          "end_time": "2024-11-21T10:49:12.969143",
          "exception": false,
          "start_time": "2024-11-21T10:49:12.954290",
          "status": "completed"
        },
        "tags": [],
        "id": "99370201"
      },
      "outputs": [],
      "source": [
        "# hide\n",
        "class ImageOriginalData(Dataset):\n",
        "    def __init__(self, files: List[str]):\n",
        "        self.files = files\n",
        "\n",
        "        self.to_tensor = transforms.PILToTensor()\n",
        "        self.resize = transforms.Resize((IMAGE_SIZE, IMAGE_SIZE))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        img = Image.open((self.files[i]))\n",
        "        img = img.convert('RGB')\n",
        "        img = self.to_tensor(img)\n",
        "\n",
        "        if  img.shape[0] == 1:\n",
        "            img = torch.cat([img]*3)\n",
        "\n",
        "        return self.resize(img)\n",
        "\n",
        "class CollateSingleImage(CollateFn):\n",
        "    def __call__(\n",
        "        self, batch: List[torch.Tensor]\n",
        "    ) -> torch.FloatTensor:\n",
        "        return self.reshape(batch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "be8a0690",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:49:12.984366Z",
          "iopub.status.busy": "2024-11-21T10:49:12.984115Z",
          "iopub.status.idle": "2024-11-21T10:51:22.067801Z",
          "shell.execute_reply": "2024-11-21T10:51:22.066903Z"
        },
        "papermill": {
          "duration": 129.100241,
          "end_time": "2024-11-21T10:51:22.076466",
          "exception": false,
          "start_time": "2024-11-21T10:49:12.976225",
          "status": "completed"
        },
        "tags": [],
        "id": "be8a0690",
        "outputId": "18c11af2-ddd9-4063-b0f8-887237822f36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.15 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-bfc214808518>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2784\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2785\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2786\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2787\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2414\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2415\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2416\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.15 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ],
      "source": [
        "files = [str(file) for file in Path(TRAIN_FILES).rglob('*') if is_image_file(str(file))]\n",
        "\n",
        "print(len(files))\n",
        "train_files, valid_files = train_test_split(files,test_size=0.15, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "33b3da4f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:51:22.092251Z",
          "iopub.status.busy": "2024-11-21T10:51:22.091965Z",
          "iopub.status.idle": "2024-11-21T10:51:22.097325Z",
          "shell.execute_reply": "2024-11-21T10:51:22.096549Z"
        },
        "papermill": {
          "duration": 0.01503,
          "end_time": "2024-11-21T10:51:22.098902",
          "exception": false,
          "start_time": "2024-11-21T10:51:22.083872",
          "status": "completed"
        },
        "tags": [],
        "id": "33b3da4f",
        "outputId": "443ae57f-ec68-41dc-80be-96b8b82aa969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_files' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-83576d42268d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m train_dl = DataLoader(\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_files' is not defined"
          ]
        }
      ],
      "source": [
        "train_data = ImageData(train_files)\n",
        "train_dl = DataLoader(\n",
        "    train_data,\n",
        "    BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=CFG.num_workers,\n",
        "    pin_memory=True,\n",
        "    collate_fn=CollateFn()\n",
        ")\n",
        "\n",
        "valid_data = ImageOriginalData(valid_files)\n",
        "valid_dl = DataLoader(\n",
        "    valid_data,\n",
        "    BATCH_SIZE*2,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=CFG.num_workers,\n",
        "    pin_memory=True,\n",
        "    collate_fn=CollateSingleImage()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "3bd426da",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:51:22.114443Z",
          "iopub.status.busy": "2024-11-21T10:51:22.114203Z",
          "iopub.status.idle": "2024-11-21T10:51:22.121275Z",
          "shell.execute_reply": "2024-11-21T10:51:22.120654Z"
        },
        "papermill": {
          "duration": 0.016558,
          "end_time": "2024-11-21T10:51:22.122762",
          "exception": false,
          "start_time": "2024-11-21T10:51:22.106204",
          "status": "completed"
        },
        "tags": [],
        "id": "3bd426da"
      },
      "outputs": [],
      "source": [
        "# Function to save checkpoint\n",
        "def save_checkpoint(model, optimizer, filename):\n",
        "    print(\"==> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "# Function to load checkpoint\n",
        "def load_checkpoint(checkpoint_file):\n",
        "    print(\"==> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=CFG.device)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"], assign=True)\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "    for state in optimizer.state.values():\n",
        "        for k, v in state.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                state[k] = v.to(CFG.device)\n",
        "\n",
        "\n",
        "def save_pkl(pkl_list,filename):\n",
        "    with open(filename, 'wb') as f:       #this will save the list as \"results.pkl\" which you can load in later\n",
        "                pkl.dump(pkl_list, f)          #as a list to python\n",
        "\n",
        "\n",
        "def load_pkl(filename):\n",
        "    with open(filename, 'rb') as f:       #this will save the list as \"results.pkl\" which you can load in later\n",
        "            pkl_list =  pkl.load(f)\n",
        "    return pkl_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "44dc7198",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:51:22.152761Z",
          "iopub.status.busy": "2024-11-21T10:51:22.152257Z",
          "iopub.status.idle": "2024-11-21T10:51:29.810379Z",
          "shell.execute_reply": "2024-11-21T10:51:29.809307Z"
        },
        "papermill": {
          "duration": 7.667897,
          "end_time": "2024-11-21T10:51:29.812217",
          "exception": false,
          "start_time": "2024-11-21T10:51:22.144320",
          "status": "completed"
        },
        "tags": [],
        "id": "44dc7198",
        "outputId": "3b188cf1-d307-4bff-a4b0-9f9e055cbf4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_dl' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-7bf82220e31f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dl' is not defined"
          ]
        }
      ],
      "source": [
        "x, y = next(iter(train_dl))\n",
        "x2 = next(iter(valid_dl))\n",
        "(x.shape, y.shape), (x2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35bfc4e8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:51:29.828697Z",
          "iopub.status.busy": "2024-11-21T10:51:29.828373Z",
          "iopub.status.idle": "2024-11-21T10:51:29.836093Z",
          "shell.execute_reply": "2024-11-21T10:51:29.835381Z"
        },
        "papermill": {
          "duration": 0.01779,
          "end_time": "2024-11-21T10:51:29.837666",
          "exception": false,
          "start_time": "2024-11-21T10:51:29.819876",
          "status": "completed"
        },
        "tags": [],
        "id": "35bfc4e8"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, d_model, n_head, n_layers):\n",
        "        super().__init__()\n",
        "        # transformer\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_head)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "\n",
        "        # positional embedding\n",
        "        w_pos = torch.randn(NUM_PATCHES, d_model) / d_model ** 0.5\n",
        "        cls_token = torch.randn(1, d_model) / d_model ** 0.5\n",
        "        self.register_parameter(\"pos_embed\", nn.Parameter(w_pos))\n",
        "        self.register_parameter(\"cls_token\", nn.Parameter(cls_token))\n",
        "\n",
        "        # pixel projection\n",
        "        self.linear = nn.Linear(2 * d_model, d_model)\n",
        "        self.norm1 = nn.LayerNorm(2 * d_model, elementwise_affine=False)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = len(x)\n",
        "        position = torch.stack([self.pos_embed] * batch_size)\n",
        "        x = torch.cat([x, position], dim=-1)\n",
        "        pixel_proj = self.norm2(F.relu(self.linear(self.norm1(x))))\n",
        "        batched_cls_token = torch.stack([self.cls_token]*batch_size)\n",
        "        cls_x = torch.cat([batched_cls_token, pixel_proj], dim=1)\n",
        "\n",
        "        cls_x.transpose_(0, 1)\n",
        "        return F.normalize(self.encoder(cls_x)[0, ...], dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33aa176e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:51:29.854049Z",
          "iopub.status.busy": "2024-11-21T10:51:29.853522Z",
          "iopub.status.idle": "2024-11-21T10:51:29.858675Z",
          "shell.execute_reply": "2024-11-21T10:51:29.857846Z"
        },
        "papermill": {
          "duration": 0.015149,
          "end_time": "2024-11-21T10:51:29.860194",
          "exception": false,
          "start_time": "2024-11-21T10:51:29.845045",
          "status": "completed"
        },
        "tags": [],
        "id": "33aa176e"
      },
      "outputs": [],
      "source": [
        "class HLoss:\n",
        "    def __init__(self, temperature_t: float, temperature_s: float):\n",
        "        self.temperature_t = temperature_t\n",
        "        self.temperature_s = temperature_s\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        t: torch.FloatTensor,\n",
        "        s: torch.FloatTensor,\n",
        "        center: torch.FloatTensor\n",
        "    ) -> torch.FloatTensor:\n",
        "        t = F.softmax((t.detach() - center.cuda()) / self.temperature_t, dim=1)\n",
        "\n",
        "        log_s = F.log_softmax(s / self.temperature_s, dim=1)\n",
        "\n",
        "        return -(t * log_s).sum(dim=1).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cace16b1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:51:29.875594Z",
          "iopub.status.busy": "2024-11-21T10:51:29.875307Z",
          "iopub.status.idle": "2024-11-21T10:51:29.881252Z",
          "shell.execute_reply": "2024-11-21T10:51:29.880418Z"
        },
        "papermill": {
          "duration": 0.015355,
          "end_time": "2024-11-21T10:51:29.882749",
          "exception": false,
          "start_time": "2024-11-21T10:51:29.867394",
          "status": "completed"
        },
        "tags": [],
        "id": "cace16b1"
      },
      "outputs": [],
      "source": [
        "# hide\n",
        "resize = transforms.Resize((IMAGE_SIZE, IMAGE_SIZE))\n",
        "\n",
        "def get_closest(embedding: torch.FloatTensor, i: int):\n",
        "    similarity = embedding @ embedding[i,:].T\n",
        "    scores, idx = similarity.topk(TOPK)\n",
        "    return scores.cpu().numpy(), idx.cpu().numpy()\n",
        "\n",
        "def get_closest_wandb_images(embedding: torch.FloatTensor, i: int, files: List[str]):\n",
        "    main_img = to_pil_image(resize(io.read_image(files[i])))\n",
        "    closest_imgs = [wandb.Image(main_img)]\n",
        "\n",
        "    scores, idx = get_closest(embedding, i)\n",
        "\n",
        "    for i, score in zip(idx, scores):\n",
        "        img = to_pil_image(resize(io.read_image(files[i])))\n",
        "        closest_imgs.append(\n",
        "            wandb.Image(img, caption=f\"{score:.4f}\")\n",
        "        )\n",
        "\n",
        "    return closest_imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb49c5d5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:51:29.898460Z",
          "iopub.status.busy": "2024-11-21T10:51:29.898209Z",
          "iopub.status.idle": "2024-11-21T10:51:29.906535Z",
          "shell.execute_reply": "2024-11-21T10:51:29.905954Z"
        },
        "papermill": {
          "duration": 0.018018,
          "end_time": "2024-11-21T10:51:29.908056",
          "exception": false,
          "start_time": "2024-11-21T10:51:29.890038",
          "status": "completed"
        },
        "tags": [],
        "id": "eb49c5d5"
      },
      "outputs": [],
      "source": [
        "class DINOLossT(nn.Module):\n",
        "    def __init__(self, out_dim, ncrops, warmup_teacher_temp, teacher_temp,\n",
        "                 warmup_teacher_temp_epochs, nepochs, student_temp=0.1,\n",
        "                 center_momentum=0.9):\n",
        "        super().__init__()\n",
        "        self.student_temp = student_temp\n",
        "        self.center_momentum = center_momentum\n",
        "        self.ncrops = ncrops\n",
        "        self.register_buffer(\"center\", torch.zeros(1, out_dim))\n",
        "        # we apply a warm up for the teacher temperature because\n",
        "        # a too high temperature makes the training instable at the beginning\n",
        "        self.teacher_temp_schedule = np.concatenate((\n",
        "            np.linspace(warmup_teacher_temp,\n",
        "                        teacher_temp, warmup_teacher_temp_epochs),\n",
        "            np.ones(nepochs - warmup_teacher_temp_epochs) * teacher_temp\n",
        "        ))\n",
        "\n",
        "    def forward(self, student_output, teacher_output, epoch):\n",
        "        \"\"\"\n",
        "        Cross-entropy between softmax outputs of the teacher and student networks.\n",
        "        \"\"\"\n",
        "        student_out = student_output / self.student_temp\n",
        "        student_out = student_out.chunk(self.ncrops)\n",
        "\n",
        "        # teacher centering and sharpening\n",
        "        temp = self.teacher_temp_schedule[epoch]\n",
        "        teacher_out = F.softmax((teacher_output - self.center) / temp, dim=-1)\n",
        "        teacher_out = teacher_out.detach().chunk(2)\n",
        "\n",
        "        total_loss = 0\n",
        "        n_loss_terms = 0\n",
        "        for iq, q in enumerate(teacher_out):\n",
        "            for v in range(len(student_out)):\n",
        "                if v == iq:\n",
        "                    # we skip cases where student and teacher operate on the same view\n",
        "                    continue\n",
        "                loss = torch.sum(-q * F.log_softmax(student_out[v], dim=-1), dim=-1)\n",
        "                total_loss += loss.mean()\n",
        "                n_loss_terms += 1\n",
        "        total_loss /= n_loss_terms\n",
        "        self.update_center(teacher_output)\n",
        "        return total_loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update_center(self, teacher_output):\n",
        "        \"\"\"\n",
        "        Update center used for teacher output.\n",
        "        \"\"\"\n",
        "        batch_center = torch.sum(teacher_output, dim=0, keepdim=True)\n",
        "        dist.all_reduce(batch_center)\n",
        "        batch_center = batch_center / (len(teacher_output) * dist.get_world_size())\n",
        "\n",
        "        # ema update\n",
        "        self.center = self.center * self.center_momentum + batch_center * (1 - self.center_momentum)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6450b3c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:51:29.923699Z",
          "iopub.status.busy": "2024-11-21T10:51:29.923441Z",
          "iopub.status.idle": "2024-11-21T10:51:29.929938Z",
          "shell.execute_reply": "2024-11-21T10:51:29.929222Z"
        },
        "papermill": {
          "duration": 0.01607,
          "end_time": "2024-11-21T10:51:29.931462",
          "exception": false,
          "start_time": "2024-11-21T10:51:29.915392",
          "status": "completed"
        },
        "tags": [],
        "id": "c6450b3c"
      },
      "outputs": [],
      "source": [
        "class DinoLoss(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        teacher: nn.Module,\n",
        "        student: nn.Module,\n",
        "        loss_fn: Callable,\n",
        "        dim: int,\n",
        "        center_momentum: float,\n",
        "        param_momentum: float,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "        self.c_mom = center_momentum\n",
        "        self.p_mom = param_momentum\n",
        "        self.register_buffer(\"center\", torch.zeros((1, dim)).float())\n",
        "\n",
        "\n",
        "    def forward(self,t1,t2,s1,s2):\n",
        "        loss = self.loss_fn(t1, s2, self.center) + self.loss_fn(t2, s1, self.center)\n",
        "        emperical_center = F.normalize(\n",
        "            torch.cat([t1, t2]).mean(dim=0, keepdims=True),\n",
        "            dim=-1,\n",
        "        )\n",
        "        self.update_center(emperical_center)\n",
        "        return loss\n",
        "\n",
        "    def update_center(self,emperical_center):\n",
        "        self.center = F.normalize(\n",
        "            self.c_mom * self.center.cuda() + (1 - self.c_mom) * emperical_center,\n",
        "            dim=-1,\n",
        "        )\n",
        "        for s_p, t_p in zip(self.student.parameters(), self.teacher.parameters()):\n",
        "            t_p.data = self.p_mom * t_p.data + (1 - self.p_mom) * s_p.data\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf308263",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:51:29.946994Z",
          "iopub.status.busy": "2024-11-21T10:51:29.946712Z",
          "iopub.status.idle": "2024-11-21T10:51:29.959045Z",
          "shell.execute_reply": "2024-11-21T10:51:29.958233Z"
        },
        "papermill": {
          "duration": 0.021826,
          "end_time": "2024-11-21T10:51:29.960537",
          "exception": false,
          "start_time": "2024-11-21T10:51:29.938711",
          "status": "completed"
        },
        "tags": [],
        "id": "cf308263"
      },
      "outputs": [],
      "source": [
        "class LightningModel(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        teacher: nn.Module,\n",
        "        lr: float,\n",
        "        loss_fn: Callable,\n",
        "        valid_files: List[str],\n",
        "        dim: int,\n",
        "        center_momentum: float,\n",
        "        param_momentum: float,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = copy.deepcopy(teacher)\n",
        "        self.lr = lr\n",
        "        self.loss_fn = loss_fn\n",
        "        self.c_mom = center_momentum\n",
        "        self.p_mom = param_momentum\n",
        "        self.register_buffer(\"center\", torch.zeros((1, dim)).float())\n",
        "        self.valid_files = valid_files\n",
        "        self.validation_step_outputs = []\n",
        "\n",
        "        for p in self.teacher.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    def loss_calculation(\n",
        "        self,\n",
        "        batch: Tuple[torch.FloatTensor, torch.FloatTensor],\n",
        "    ) -> torch.FloatTensor:\n",
        "        x1, x2 = batch\n",
        "\n",
        "        s1, s2 = self.student(x1), self.student(x2)\n",
        "        t1, t2 = self.teacher(x1), self.teacher(x2)\n",
        "\n",
        "        loss = self.loss_fn(t1, s2, self.center) + self.loss_fn(t2, s1, self.center)\n",
        "\n",
        "        emperical_center = F.normalize(\n",
        "            torch.cat([t1, t2]).mean(dim=0, keepdims=True),\n",
        "            dim=-1,\n",
        "        )\n",
        "        return loss, emperical_center\n",
        "\n",
        "    def training_step(\n",
        "        self, batch: Tuple[torch.FloatTensor, torch.FloatTensor], *args: List[Any]\n",
        "    ) -> torch.Tensor:\n",
        "        loss, emperical_center = self.loss_calculation(batch)\n",
        "        self.log(name=\"Training loss\", value=loss, on_step=True, on_epoch=True)\n",
        "\n",
        "        self.center = F.normalize(\n",
        "            self.c_mom * self.center + (1 - self.c_mom) * emperical_center,\n",
        "            dim=-1,\n",
        "        )\n",
        "        for s_p, t_p in zip(self.student.parameters(), self.teacher.parameters()):\n",
        "            t_p.data = self.p_mom * t_p.data + (1 - self.p_mom) * s_p.data\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, images: torch.FloatTensor, *args: List[Any]) -> None:\n",
        "        return self.validation_step_outputs.append(self.teacher(images))\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        valid_embeds = torch.cat([pred for pred in self.validation_step_outputs])\n",
        "        columns = [\"image\"] + [f\"closest_{i+1}\" for i in range(TOPK)]\n",
        "        indices = np.random.choice(len(self.valid_files), VALID_IMAGES, replace=False)\n",
        "        rows = [get_closest_wandb_images(valid_embeds, i, self.valid_files) for i in indices]\n",
        "        table = wandb.Table(data=rows, columns=columns)\n",
        "        self.logger.experiment.log({f\"epoch {self.current_epoch} results\": table})\n",
        "        self.validation_step_outputs.clear()\n",
        "\n",
        "    def on_after_backward(self):\n",
        "        if self.trainer.global_step % 50 == 0:  # don't make the tf file huge\n",
        "            global_step = self.trainer.global_step\n",
        "            for name, param in self.student.named_parameters():\n",
        "                if \"weight\" in name and not \"norm\" in name and param.requires_grad:\n",
        "                    self.logger.experiment.log(\n",
        "                        {f\"{name}_grad\": wandb.Histogram(param.grad.cpu())}\n",
        "                    )\n",
        "\n",
        "    def configure_optimizers(self) -> torch.optim.Optimizer:\n",
        "        return FusedAdam(self.student.parameters(), lr=self.lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0695a0da",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:51:29.976415Z",
          "iopub.status.busy": "2024-11-21T10:51:29.975710Z",
          "iopub.status.idle": "2024-11-21T10:51:29.983093Z",
          "shell.execute_reply": "2024-11-21T10:51:29.982485Z"
        },
        "papermill": {
          "duration": 0.016906,
          "end_time": "2024-11-21T10:51:29.984650",
          "exception": false,
          "start_time": "2024-11-21T10:51:29.967744",
          "status": "completed"
        },
        "tags": [],
        "id": "0695a0da"
      },
      "outputs": [],
      "source": [
        "\n",
        "def training_one_epoch(train_dataloader, epoch, loss_fn, student, teacher, optimizer):\n",
        "#                       teacher_without_ddp, lr_schedule, momentum_schedule, fp16_scaler, args):\n",
        "\n",
        "        student.train()\n",
        "        teacher.train()\n",
        "        losses=[]\n",
        "        metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "        header = 'Epoch: [{}/{}]'.format(epoch, CFG.EPOCHS)\n",
        "\n",
        "        for p in teacher.parameters():\n",
        "            p.requires_grad = False\n",
        "        for i, data in enumerate(metric_logger.log_every(train_dataloader, 10, header)):\n",
        "        #for i, data in enumerate(loop,0):\n",
        "            img1, img2 = data\n",
        "            img1, img2 = img1.to(device), img2.to(device)\n",
        "            for param in teacher.parameters():\n",
        "              param.grad = None\n",
        "            for param in student.parameters():\n",
        "              param.grad = None\n",
        "            s1, s2 = student(img1), student(img2)\n",
        "            t1, t2 = teacher(img1), teacher(img2)\n",
        "            loss = loss_fn(t1,t2,s1,s2)\n",
        "            if not math.isfinite(loss.item()):\n",
        "                print(\"Loss is {}, stopping training\".format(loss.item()), force=True)\n",
        "                sys.exit(1)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses.append(loss.item())\n",
        "            mean_loss =  np.mean(losses)\n",
        "            # loop.set_description(f\"Epoch [{epoch}/{CFG.EPOCHS}]\")\n",
        "            # loop.set_postfix(Loss=mean_loss)\n",
        "\n",
        "            metric_logger.update(loss=loss.item())\n",
        "            metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
        "            metric_logger.update(wd=optimizer.param_groups[0][\"weight_decay\"])\n",
        "\n",
        "        print(\"Averaged stats:\", metric_logger)\n",
        "        return {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8035fdf",
      "metadata": {
        "papermill": {
          "duration": 0.00703,
          "end_time": "2024-11-21T10:51:29.999036",
          "exception": false,
          "start_time": "2024-11-21T10:51:29.992006",
          "status": "completed"
        },
        "tags": [],
        "id": "c8035fdf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a8268c15",
      "metadata": {
        "papermill": {
          "duration": 0.006997,
          "end_time": "2024-11-21T10:51:30.013603",
          "exception": false,
          "start_time": "2024-11-21T10:51:30.006606",
          "status": "completed"
        },
        "tags": [],
        "id": "a8268c15"
      },
      "source": [
        "Thanks to PyTorch Lightning and WandB I can easily do half precision training and log the results to a beautiful dashboard, with results in the link below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5151fa4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:51:30.029434Z",
          "iopub.status.busy": "2024-11-21T10:51:30.028796Z",
          "iopub.status.idle": "2024-11-21T10:51:31.283029Z",
          "shell.execute_reply": "2024-11-21T10:51:31.281845Z"
        },
        "papermill": {
          "duration": 1.264323,
          "end_time": "2024-11-21T10:51:31.285126",
          "exception": false,
          "start_time": "2024-11-21T10:51:30.020803",
          "status": "completed"
        },
        "tags": [],
        "id": "f5151fa4"
      },
      "outputs": [],
      "source": [
        "!mkdir /kaggle/working/logs\n",
        "teacher = Model(NUM_PIXELS, N_HEADS, N_LAYERS).to(device)\n",
        "student = copy.deepcopy(teacher)\n",
        "optimizer = torch.optim.AdamW(student.parameters(), lr=LR)\n",
        "h_loss = HLoss(TEMPERATURE_T, TEMPERATURE_S)\n",
        "dino_loss = DinoLoss(\n",
        "    teacher,\n",
        "    student,\n",
        "    h_loss,\n",
        "    NUM_PIXELS,\n",
        "    CENTER_MOMENTUM,\n",
        "    TEACHER_MOMENTUM,\n",
        ")\n",
        "\n",
        "#logger = WandbLogger(\"DINO\", \"/kaggle/working/logs/\", project=\"DINO\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41ec6d3e",
      "metadata": {
        "papermill": {
          "duration": 0.007198,
          "end_time": "2024-11-21T10:51:31.300084",
          "exception": false,
          "start_time": "2024-11-21T10:51:31.292886",
          "status": "completed"
        },
        "tags": [],
        "id": "41ec6d3e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc311df4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:51:31.316293Z",
          "iopub.status.busy": "2024-11-21T10:51:31.315988Z",
          "iopub.status.idle": "2024-11-21T10:51:31.323644Z",
          "shell.execute_reply": "2024-11-21T10:51:31.322807Z"
        },
        "papermill": {
          "duration": 0.01805,
          "end_time": "2024-11-21T10:51:31.325403",
          "exception": false,
          "start_time": "2024-11-21T10:51:31.307353",
          "status": "completed"
        },
        "tags": [],
        "id": "dc311df4"
      },
      "outputs": [],
      "source": [
        "def training_model(epochs= CFG.EPOCHS):\n",
        "  train_loss=[]\n",
        "  eval_loss=[]\n",
        "  for epoch in range(0,epochs):\n",
        "        train_stats = training_one_epoch(train_dataloader=train_dl, epoch=epoch, loss_fn=dino_loss, student=student, teacher=teacher, optimizer=optimizer)\n",
        "        # ============ writing logs ... ============\n",
        "        save_dict = {\n",
        "            'student': student.state_dict(),\n",
        "            'teacher': teacher.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'epoch': epoch + 1,\n",
        "            #'args': args,\n",
        "            'dino_loss': dino_loss.state_dict(),\n",
        "        }\n",
        "        utils.save_on_master(save_dict, os.path.join(CFG.output_dir, 'checkpoint.pth'))\n",
        "        utils.save_on_master(save_dict, os.path.join(CFG.output_dir, f'checkpoint{epoch:04}.pth'))\n",
        "        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
        "                     'epoch': epoch}\n",
        "        if utils.is_main_process():\n",
        "            with (Path(CFG.output_dir) / \"log.txt\").open(\"a\") as f:\n",
        "                f.write(json.dumps(log_stats) + \"\\n\")\n",
        "  total_time = time.time() - start_time\n",
        "  total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "  print('Training time {}'.format(total_time_str))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2351c46a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-21T10:51:31.340898Z",
          "iopub.status.busy": "2024-11-21T10:51:31.340634Z",
          "iopub.status.idle": "2024-11-21T12:49:41.346754Z",
          "shell.execute_reply": "2024-11-21T12:49:41.345425Z"
        },
        "papermill": {
          "duration": 7090.015685,
          "end_time": "2024-11-21T12:49:41.348370",
          "exception": true,
          "start_time": "2024-11-21T10:51:31.332685",
          "status": "failed"
        },
        "tags": [],
        "id": "2351c46a"
      },
      "outputs": [],
      "source": [
        "training_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3491ead4",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "3491ead4"
      },
      "source": [
        "## Evaluate results\n",
        "Finally lets look at some random images with its most closest images according to the model. Note that at this point, we throw away the student and simply take the teacher, even though it is only the student that used gradient information directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdf6a9fc",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "cdf6a9fc"
      },
      "outputs": [],
      "source": [
        "# hide\n",
        "image_orig_data = ImageOriginalData(files)\n",
        "image_orig_dl = DataLoader(\n",
        "    image_orig_data,\n",
        "    BATCH_SIZE*2,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    collate_fn=CollateSingleImage(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "076eebdb",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "076eebdb"
      },
      "outputs": [],
      "source": [
        "teacher = teacher.eval().to(device)\n",
        "embedding = []\n",
        "with torch.no_grad():\n",
        "    for x in tqdm(image_orig_dl):\n",
        "        out = teacher(x.to(device))\n",
        "        embedding.append(out.cpu())\n",
        "\n",
        "    embedding = torch.cat(embedding, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f238560",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "3f238560"
      },
      "outputs": [],
      "source": [
        "def plot_closest_pairs(embedding, i, files):\n",
        "    img = to_pil_image(resize(io.read_image(files[i])))\n",
        "    plt.imshow(img)\n",
        "    scores, idx = get_closest(embedding, i)\n",
        "\n",
        "    fig, axs = plt.subplots(1, len(idx), figsize=(12, 5))\n",
        "    for i, score, ax in zip(idx, scores, axs):\n",
        "        img = to_pil_image(resize(io.read_image(files[i])))\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(f\"{score:.4f}\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "820f400e",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "820f400e"
      },
      "outputs": [],
      "source": [
        "i = 64\n",
        "plot_closest_pairs(embedding, i, files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef2f5ead",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "ef2f5ead"
      },
      "outputs": [],
      "source": [
        "i = 42\n",
        "plot_closest_pairs(embedding, i, files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b48cd8f4",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "b48cd8f4"
      },
      "outputs": [],
      "source": [
        "i = 21\n",
        "plot_closest_pairs(embedding, i, files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b4dff4",
      "metadata": {
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "83b4dff4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4870161,
          "sourceId": 8216498,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 6112873,
          "sourceId": 9950651,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 7290.61924,
      "end_time": "2024-11-21T12:49:44.510535",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-11-21T10:48:13.891295",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}